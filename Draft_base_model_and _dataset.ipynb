{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pretrainedmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 torch.Size([1, 3, 64, 64]) torch.Size([1, 200])\n",
      "se_resnet50 torch.Size([1, 3, 64, 64]) torch.Size([1, 200])\n",
      "se_resnext50_32x4d torch.Size([1, 3, 64, 64]) torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "model_names = [ 'resnet50', 'se_resnet50', 'se_resnext50_32x4d']\n",
    "\n",
    "\n",
    "class WrapperModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_model_name):\n",
    "        super(WrapperModel, self).__init__()\n",
    "        \n",
    "        assert(base_model_name in model_names)\n",
    "        \n",
    "        base_model = pretrainedmodels.__dict__[base_model_name](pretrained='imagenet')\n",
    "        \n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-2])        \n",
    "        \n",
    "        feature_num = base_model.last_linear.in_features\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.last_linear = nn.Linear(feature_num, 200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    image = torch.randn(1,3,64,64)\n",
    "    for model_name in model_names:\n",
    "        model = WrapperModel(model_name)\n",
    "        out = model(image)\n",
    "        print(model_name,image.shape, out.shape)\n",
    "        \n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tiny-imagenet-200/train/n04074963/images/n04074963_130.JPEG n04074963 54\n",
      "val_0.JPEG n03444034 163\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image \n",
    "import numpy as np    \n",
    "\n",
    "\n",
    "def load_wnids(path='../tiny-imagenet-200/wnids.txt'):\n",
    "    with open(path) as f:\n",
    "        wnids = f.readlines()\n",
    "        assert len(wnids) == 200\n",
    "        wnids = [x.strip() for x in wnids]\n",
    "    class2idx = {wnids[i]:i  for i in range(len(wnids))}\n",
    "    return wnids, class2idx\n",
    "\n",
    "class TinyTrainset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, wnids_path, transform=None):\n",
    "        super(TinyTrainset, self).__init__()\n",
    "        classes = [d.name for d in os.scandir(root) if d.is_dir()]\n",
    "        image_lists = [glob.glob(os.path.join(root, cls, 'images','*.JPEG'))  for cls in classes]\n",
    "        \n",
    "        self.images = []\n",
    "        for image_list in image_lists:\n",
    "            self.images += image_list\n",
    "        labels = [ image.split('/')[-1].split('_')[0] for image in self.images]   \n",
    "        \n",
    "        self.wnids, self.class_to_idx = load_wnids(wnids_path)\n",
    "        self.idxs = [ self.class_to_idx[label] for label in labels]\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "        assert(len(self.wnids)==200 and len(self.images)==200*500)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        image = Image.open(self.images[index])\n",
    "        label_idx = self.idxs[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "        \n",
    "\n",
    "class TinyValset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, wnids_path, ann_path, transform=None):\n",
    "        super(TinyValset, self).__init__()\n",
    "        \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.wnids, self.class_to_idx = load_wnids(wnids_path)\n",
    "        \n",
    "        with open(ann_path) as f:\n",
    "            labels = f.readlines()\n",
    "            assert len(labels) == 10000        \n",
    "            data = [ label.split('\\t')[:2] for label in labels]\n",
    "            self.images, self.image_labels = zip(*data)        \n",
    "        self.idxs = [ self.class_to_idx[label] for label in self.image_labels]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        image = Image.open(os.path.join(self.root, self.images[index]))\n",
    "        label_idx = self.idxs[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx        \n",
    "        \n",
    "def test_trainset():\n",
    "    root = '../tiny-imagenet-200/train/'\n",
    "    wnids_path = '../tiny-imagenet-200/wnids.txt'\n",
    "    \n",
    "    trainset = TinyTrainset(root, wnids_path)\n",
    "    sample = trainset[0]\n",
    "    image, label = sample\n",
    "    image = np.array(image)\n",
    "    assert image.shape == (64, 64, 3)\n",
    "    assert 0 <= label and label < 200\n",
    "    \n",
    "    print(trainset.images[0], trainset.labels[0], trainset.idxs[0])\n",
    "    \n",
    "def test_valset():\n",
    "    root = '../tiny-imagenet-200/val/images/'\n",
    "    wnids_path = '../tiny-imagenet-200/wnids.txt'\n",
    "    ann_path = '../tiny-imagenet-200/val/val_annotations.txt'\n",
    "    \n",
    "    valset = TinyValset(root, wnids_path, ann_path)\n",
    "    image, label = valset[0]\n",
    "    image = np.array(image)\n",
    "    \n",
    "    assert image.shape == (64, 64, 3)\n",
    "    assert 0 <= label and label < 200    \n",
    "    \n",
    "    print(valset.images[0], valset.image_labels[0], valset.idxs[0])\n",
    "    \n",
    "test_trainset()\n",
    "test_valset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
